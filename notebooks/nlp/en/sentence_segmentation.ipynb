{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import unidecode\n",
    "\n",
    "# Tika imports\n",
    "import tika.parser\n",
    "\n",
    "# NLTK imports\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters, PunktTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup default path for documents\n",
    "document_path = \"/data/workspace/lexpredict-contraxsuite-samples/\"\n",
    "document_type = \"txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_file_list(path, extension=None):\n",
    "    file_list = []\n",
    "    for file_name in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, file_name)):\n",
    "            file_list.extend(build_file_list(os.path.join(path, file_name)))\n",
    "        elif os.path.isfile(os.path.join(path, file_name)):\n",
    "            if extension and file_name.lower().endswith(extension.lower()):\n",
    "                file_list.append(os.path.join(path, file_name))\n",
    "            else:\n",
    "                file_list.append(os.path.join(path, file_name))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 100 files...\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/agreements/construction/1040596_2001-11-14_CONSTRUCTION AGREEMENT DATED AUGUST 29, 2001.txt\n",
      "total abbreviations found: 2\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/plans/retirement/819793_2008-01-02_SUPPLEMENTAL EXECUTIVE RETIREMENT PLAN.txt\n",
      "total abbreviations found: 31\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/agreements/employment/700565_2010-05-03_EMPLOYMENT AGREEMENTS.txt\n",
      "total abbreviations found: 45\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/agreements/credit/896778_2011-08-26_CREDIT AGREEMENT.txt\n",
      "total abbreviations found: 52\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/agreements/severance/810130_1999-02-26_SEVERANCE AGREEMENT.txt\n",
      "total abbreviations found: 59\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/agreements/software_license/1414043_2016-10-14_SOFTWARE LICENSE AGREEMENT DATED OCTOBER 7, 2016 BY AND BETWEEN THE COMPANY AND HANG WITH, INC..txt\n",
      "total abbreviations found: 67\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/agreements/employment/909990_2006-08-28_FIRST AMENDMENT TO EMPLOYMENT AGREEMENT.txt\n",
      "total abbreviations found: 71\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/agreements/construction/1044827_1998-05-15_AMENDMENT NO. 1 TO PRE-CONSTRUCTION IR4 AGMT.txt\n",
      "total abbreviations found: 78\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/plans/retirement/107832_2008-12-12_FORM OF SUPPLEMENTAL RETIREMENT PLAN AGMT. - HARVEY, PROTSCH, SWAN.txt\n",
      "total abbreviations found: 84\n",
      "training on: /data/workspace/lexpredict-contraxsuite-samples/agreements/employment/1220379_2007-06-27_EMPLOYMENT AGREEMENT WITH L. FRED HUGGINS, DATED MAY 21, 2007.txt\n",
      "total abbreviations found: 88\n"
     ]
    }
   ],
   "source": [
    "# Iterate through file list            \n",
    "file_list = build_file_list(document_path, \"txt\")\n",
    "\n",
    "# Get random sample of N\n",
    "M = 10\n",
    "N = 100\n",
    "from numpy.random import choice\n",
    "file_list = choice(file_list, N)\n",
    "\n",
    "# Setup tokenizer\n",
    "punkt_trainer = PunktTrainer()\n",
    "\n",
    "print(\"training on {0} files...\".format(len(file_list)))\n",
    "i = 0\n",
    "for file_name in file_list:\n",
    "    # Load document\n",
    "    tika_response = tika.parser.from_file(os.path.join(document_path, file_name))\n",
    "    try:\n",
    "        tika_content = unidecode.unidecode(tika_response[\"content\"])\n",
    "    except KeyError as e:\n",
    "        continue\n",
    "    punkt_trainer.train(tika_content, verbose=False, finalize=False)\n",
    "    \n",
    "    # Add to text buffer\n",
    "    if i % 10 == 0:\n",
    "        print(\"training on: {0}\".format(file_name))\n",
    "        print(\"total abbreviations found: {0}\".format(len(punkt_trainer._params.abbrev_types)))\n",
    "    i += 1\n",
    "    \n",
    "punkt_trainer.train(\"This is the exemption section of the I.R.C.\", verbose=False, finalize=False)\n",
    "punkt_trainer.finalize_training(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total abbreviations: 125\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer and test\n",
    "punkt_params = punkt_trainer.get_params()\n",
    "\n",
    "# Add required set\n",
    "required_list = [\n",
    "    # Entity types\n",
    "    'Inc.', 'L.L.C.', 'Ltd.', 'L.P.', 'S.A.',\n",
    " 'INC.', 'S.A. de C.V.', 'S. de R.L. de C.V.', 'S.L.', 'Inc.',\n",
    " 'LTD.', 'B.V.', 'LLC.', 'Lda.', 'Ltda.', 'S.R.L.', 's.r.o.',\n",
    " 'S.A.S.', 'S.A. DE C.V.', 'C.A.', 'Corp.', 'S.L.U.', 'S.A. De C.V.',\n",
    " 'S. DE R.L. DE C.V.', 'L.L.P.','K.K.', 'C.V.', 'N.A.', 'Ltd.', 'S.r.l.',\n",
    " 'S.A.R.L.', 'S. de R. L. de C.V.', 'S. De R.L. De C.V.', 'S.R.L. de C.V.', 'G.P.',\n",
    " 'S.A.de C.V.', 'L.P.', 'N.V.', 'S de R.L. de C.V.', 'S.C.A.',\n",
    " 'Sdn. Bhd.', 'S.R.O.', 'L.L.L.P.', 'S.de R.L. de C.V.', 'Pte. Ltd.',\n",
    " 'S.A.U.', 'S.C.', 'S.a.r.l.', 'S. De R.L. de C.V.',\n",
    "    # Court/regulatory abbreviations\n",
    "    'U.S.', 'U.S.C.', 'I.R.S.', 'Treas.', \n",
    "    'Tex.', 'Bus.', 'Com.',\n",
    "    \n",
    "    # Honorifics\n",
    "    'Mr', 'Ms', 'Mrs', 'Dr', 'Prof', 'Sr', 'Jr',\n",
    "                ]\n",
    "\n",
    "for abbrev in required_list:\n",
    "    punkt_params.abbrev_types.add(abbrev.strip(\".\").lower())\n",
    "\n",
    "tokenizer = PunktSentenceTokenizer(punkt_params)\n",
    "print(\"total abbreviations: {0}\".format(len(punkt_params.abbrev_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batman, Esq., J.D., M.B.A., is the author of 26 U.S.C. 501, i.e., the exemption section of the IRC.',\n",
       " 'Therefore, e.g., joke about INC. or LLC. entities run by Dr. Brown.',\n",
       " 'Did you know that the I.R.S. loves to fine non-U.S. Acme Ltda. at c.a. 10:00A.M.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"\"\"Batman, Esq., J.D., M.B.A., is the author of 26 U.S.C. 501, i.e., the exemption section of the IRC.\n",
    "Therefore, e.g., joke about INC. or LLC. entities run by Dr. Brown.\n",
    "Did you know that the I.R.S. loves to fine non-U.S. Acme Ltda. at c.a. 10:00A.M.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Employee acknowledges that the Confidential Information provided to Employee pursuant to this Agreement, and Company’s need to protect its goodwill,\\ngives rise to Company’s interest in these restrictive covenants, and that any limitations as to time, geographic scope, and scope of activity to be restrained defined herein are reasonable and do not impose a greater restraint than is necessary\\nto protect the goodwill or other business interest of Company.',\n",
       " 'The Employee further agrees that if, at some later date, a court of competent jurisdiction determines that these covenants do not meet the criteria set forth in Tex. Bus. & Com.\\nCode § 15.50(2), these agreements shall be reformed by the court, pursuant to Tex. Bus. & Com. Code § 15.51(c), by the least extent necessary to make them enforceable.',\n",
       " 'Employee acknowledges and recognizes that the enforcement of\\nany of the provisions in this Agreement by Company will not interfere with the Employee’s ability to pursue a proper livelihood.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"\"\"Employee acknowledges that the Confidential Information provided to Employee pursuant to this Agreement, and Company’s need to protect its goodwill,\n",
    "gives rise to Company’s interest in these restrictive covenants, and that any limitations as to time, geographic scope, and scope of activity to be restrained defined herein are reasonable and do not impose a greater restraint than is necessary\n",
    "to protect the goodwill or other business interest of Company. The Employee further agrees that if, at some later date, a court of competent jurisdiction determines that these covenants do not meet the criteria set forth in Tex. Bus. & Com.\n",
    "Code § 15.50(2), these agreements shall be reformed by the court, pursuant to Tex. Bus. & Com. Code § 15.51(c), by the least extent necessary to make them enforceable. Employee acknowledges and recognizes that the enforcement of\n",
    "any of the provisions in this Agreement by Company will not interfere with the Employee’s ability to pursue a proper livelihood.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batman, Esq., J.D., M.B.A., is the author of 26 U.S.C.',\n",
       " '501, i.e., the exemption section of the I.R.C.',\n",
       " 'Therefore, e.g., joke about INC. or LLC.',\n",
       " 'entities.',\n",
       " 'Did you know that the I.R.S.',\n",
       " 'loves to fine non-U.S. Acme Ltda.',\n",
       " 'at c.a.',\n",
       " '10:00A.M.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.sent_tokenize(\"\"\"Batman, Esq., J.D., M.B.A., is the author of 26 U.S.C. 501, i.e., the exemption section of the I.R.C.\n",
    "Therefore, e.g., joke about INC. or LLC. entities.\n",
    "Did you know that the I.R.S. loves to fine non-U.S. Acme Ltda. at c.a. 10:00A.M.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the tokenizer\n",
    "with open(\"../../../lexnlp/nlp/en/sentence_segmenter.pickle\", \"wb\") as out_file:\n",
    "    pickle.dump(tokenizer, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
